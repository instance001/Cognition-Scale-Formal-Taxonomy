# The Cognition Scale (Plain English Overview)

The Cognition Scale is a simple way to understand **all kinds of minds**, whether
they are human or artificial. Instead of arguing about “AI vs humans,” it sorts
every thinking system into **four clear types**, based on how they actually work
on the inside.

This makes it easy for anyone—engineers, policymakers, psychologists, or
curious people—to talk about different intelligence systems without confusion.

---

# The Four Kinds of Minds

### **1. LCM — Large Cognition Model (Humans)**
Humans are the most complex minds we know.
We learn from life, feel emotions, make judgement calls, and think in flexible,
creative ways. Humans are the “gold standard” for what a real mind is.

---

### **2. LLM — Large Language Model (ChatGPT, Claude, Gemini, etc.)**
These are huge text models that guess the next word really well.
They can sound smart, but they don’t understand the world the way humans do.
They can make mistakes (“hallucinations”) or switch tone (“persona drift”)
because they work by patterns, not reasoning.

---

### **3. MCM — Modest Cognition Model (Janet)**
This is a **new kind of AI** created to be:
- safe  
- predictable  
- transparent  
- limited on purpose  

An MCM doesn’t guess or pretend — it follows clear logic steps, uses inspected
memory, and builds skills one by one with human review. It never hallucinates.
If it doesn’t know, it simply says so.

This is the first AI class built specifically for **reliability and safety**, not
for sounding human.

---

### **4. SCM — Simple Cognition Model (rules, scripts, game AI, automation)**
These are basic logic systems: “if X, do Y.”
They don’t learn, grow, or reason. They’re simple, predictable tools.

---

# Why This Scale Exists

Today, people mix up very different systems under the word “AI.”
This causes arguments, mistakes, and bad policy.

The Cognition Scale fixes that by giving everyone a shared vocabulary.

It helps:
- engineers build the right tools  
- scientists compare cognition across biology and machines  
- policymakers regulate systems based on actual risk  
- educators explain AI clearly  
- the public understand what different systems can (and can’t) do  

---

# A Simple Way to See It

- **Humans** → complex minds  
- **LLMs** → giant pattern machines  
- **MCMs** → safe, logical tool minds  
- **SCMs** → simple rule logic  

That’s it.  
Four clean categories.  
No hype. No magic. No confusion.

---

# License
This entire framework is open-source under AGPLv3.  
Anyone can use it, improve it, or build on it—just share your changes back.
